# GaussianHaircut æ›¿ä»£ç»„ä»¶æ–¹æ¡ˆ

æœ¬æ–‡æ¡£æä¾›äº†é¡¹ç›®ä¸­å„ä¸ªç»„ä»¶çš„ Windows å‹å¥½æ›¿ä»£æ–¹æ¡ˆï¼Œå¸®åŠ©è§£å†³ç¼–è¯‘å›°éš¾æˆ–å…¼å®¹æ€§é—®é¢˜ã€‚

## ğŸ¯ æ›¿ä»£æ–¹æ¡ˆä¼˜å…ˆçº§

| ä¼˜å…ˆçº§ | è¯´æ˜ | é€‚ç”¨åœºæ™¯ |
|--------|------|----------|
| ğŸŸ¢ æ¨è | æ˜“äºå®‰è£…ï¼Œæ€§èƒ½å¥½ï¼Œå…¼å®¹æ€§é«˜ | é¦–é€‰æ–¹æ¡ˆ |
| ğŸŸ¡ å¯é€‰ | éœ€è¦é¢å¤–é…ç½®ï¼Œä½†å¯è¡Œ | å¤‡é€‰æ–¹æ¡ˆ |
| ğŸ”´ ä¸æ¨è | å¯èƒ½æœ‰å…¼å®¹æ€§é—®é¢˜ | æœ€åé€‰æ‹© |

---

## 1. OpenPose æ›¿ä»£æ–¹æ¡ˆ

### é—®é¢˜
- Windows ç¼–è¯‘å¤æ‚ï¼Œéœ€è¦ Visual Studio + CUDA + cuDNN
- ä¾èµ–å¤šï¼Œå®¹æ˜“å‡ºé”™
- ç¼–è¯‘æ—¶é—´é•¿ï¼ˆ1-2 å°æ—¶ï¼‰

### ğŸŸ¢ æ–¹æ¡ˆ 1: MediaPipe (å¼ºçƒˆæ¨è)

**ä¼˜åŠ¿**:
- âœ… çº¯ Pythonï¼Œæ— éœ€ç¼–è¯‘
- âœ… è·¨å¹³å°ï¼ŒWindows å®Œç¾æ”¯æŒ
- âœ… æ€§èƒ½ä¼˜ç§€ï¼Œå®æ—¶å¤„ç†
- âœ… Google ç»´æŠ¤ï¼Œæ›´æ–°æ´»è·ƒ

**å®‰è£…**:
```powershell
pip install mediapipe opencv-python
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
import mediapipe as mp
import cv2
import numpy as np

# åˆå§‹åŒ– MediaPipe Pose
mp_pose = mp.solutions.pose
mp_drawing = mp.solutions.drawing_utils
pose = mp_pose.Pose(
    static_image_mode=True,
    model_complexity=2,
    enable_segmentation=False,
    min_detection_confidence=0.5
)

# å¤„ç†å›¾åƒ
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
results = pose.process(image_rgb)

# è·å–å…³é”®ç‚¹
if results.pose_landmarks:
    landmarks = results.pose_landmarks.landmark
    # è½¬æ¢ä¸º OpenPose æ ¼å¼
    keypoints = []
    for landmark in landmarks:
        keypoints.append([
            landmark.x * image.shape[1],
            landmark.y * image.shape[0],
            landmark.visibility
        ])
```

**å…³é”®ç‚¹æ˜ å°„**:
```python
# MediaPipe åˆ° OpenPose çš„å…³é”®ç‚¹æ˜ å°„
MEDIAPIPE_TO_OPENPOSE = {
    0: 0,   # é¼»å­
    11: 2,  # å·¦è‚©
    12: 5,  # å³è‚©
    13: 3,  # å·¦è‚˜
    14: 6,  # å³è‚˜
    15: 4,  # å·¦æ‰‹è…•
    16: 7,  # å³æ‰‹è…•
    # ... æ›´å¤šæ˜ å°„
}
```

**é›†æˆåˆ°é¡¹ç›®**:
```powershell
# ä¿®æ”¹ src/preprocessing/detect_keypoints.py
# å°† OpenPose è°ƒç”¨æ›¿æ¢ä¸º MediaPipe
```

### ğŸŸ¢ æ–¹æ¡ˆ 2: MMPose (æ¨è)

**ä¼˜åŠ¿**:
- âœ… æ˜“äºå®‰è£…
- âœ… å¤šç§é¢„è®­ç»ƒæ¨¡å‹
- âœ… OpenMMLab ç”Ÿæ€ç³»ç»Ÿ
- âœ… Windows æ”¯æŒå¥½

**å®‰è£…**:
```powershell
pip install openmim
mim install mmcv
mim install mmpose
mim install mmdet  # ç”¨äºäººä½“æ£€æµ‹
```

**ä½¿ç”¨ç¤ºä¾‹**:
```python
from mmpose.apis import init_model, inference_topdown
from mmdet.apis import init_detector, inference_detector

# åˆå§‹åŒ–æ£€æµ‹å™¨å’Œå§¿æ€ä¼°è®¡å™¨
det_config = 'demo/mmdetection_cfg/faster_rcnn_r50_fpn_coco.py'
det_checkpoint = 'https://download.openmmlab.com/mmdetection/v2.0/faster_rcnn/faster_rcnn_r50_fpn_1x_coco/faster_rcnn_r50_fpn_1x_coco_20200130-047c8118.pth'
detector = init_detector(det_config, det_checkpoint, device='cuda:0')

pose_config = 'configs/body_2d_keypoint/topdown_heatmap/coco/td-hm_hrnet-w48_8xb32-210e_coco-256x192.py'
pose_checkpoint = 'https://download.openmmlab.com/mmpose/top_down/hrnet/hrnet_w48_coco_256x192-b9e0b3ab_20200708.pth'
pose_model = init_model(pose_config, pose_checkpoint, device='cuda:0')

# æ¨ç†
image = 'image.jpg'
det_results = inference_detector(detector, image)
pose_results = inference_topdown(pose_model, image, det_results)
```

### ğŸŸ¡ æ–¹æ¡ˆ 3: AlphaPose

**ä¼˜åŠ¿**:
- âœ… å‡†ç¡®åº¦é«˜
- âœ… æ”¯æŒå¤šäººå§¿æ€ä¼°è®¡
- âš ï¸ éœ€è¦ç¼–è¯‘éƒ¨åˆ†ç»„ä»¶

**å®‰è£…**:
```powershell
git clone https://github.com/MVIG-SJTU/AlphaPose.git
cd AlphaPose
pip install -r requirements.txt
python setup.py build develop
```

### ğŸŸ¡ æ–¹æ¡ˆ 4: OpenPose é¢„ç¼–è¯‘ç‰ˆæœ¬

**ä¸‹è½½**:
- https://github.com/CMU-Perceptual-Computing-Lab/openpose/releases
- é€‰æ‹© Windows é¢„ç¼–è¯‘ç‰ˆæœ¬

**ä½¿ç”¨**:
```powershell
# è§£å‹åˆ° ext/openpose
# ä½¿ç”¨ Python API
import sys
sys.path.append('ext/openpose/build/python/openpose/Release')
import pyopenpose as op
```

---

## 2. COLMAP æ›¿ä»£æ–¹æ¡ˆ

### é—®é¢˜
- Conda ç‰ˆæœ¬å¯èƒ½ä¸ç¨³å®š
- ç¼–è¯‘å¤æ‚

### ğŸŸ¢ æ–¹æ¡ˆ 1: é¢„ç¼–è¯‘ COLMAP (æ¨è)

**ä¸‹è½½**:
```powershell
# ä»å®˜æ–¹ GitHub ä¸‹è½½
# https://github.com/colmap/colmap/releases
# ä¸‹è½½ COLMAP-3.8-windows-cuda.zip æˆ–æ›´é«˜ç‰ˆæœ¬

# è§£å‹å¹¶æ·»åŠ åˆ° PATH
$env:Path += ";C:\path\to\colmap\bin"

# éªŒè¯
colmap -h
```

### ğŸŸ¡ æ–¹æ¡ˆ 2: OpenMVG

**ä¼˜åŠ¿**:
- âœ… å¼€æº SfM åº“
- âœ… Windows æ”¯æŒ
- âš ï¸ åŠŸèƒ½ç•¥å°‘äº COLMAP

**å®‰è£…**:
```powershell
# ä¸‹è½½é¢„ç¼–è¯‘ç‰ˆæœ¬
# https://github.com/openMVG/openMVG/releases

# æˆ–ä½¿ç”¨ vcpkg
vcpkg install openmvg
```

### ğŸŸ¡ æ–¹æ¡ˆ 3: Meshroom

**ä¼˜åŠ¿**:
- âœ… GUI ç•Œé¢
- âœ… AliceVision å¼•æ“
- âœ… Windows åŸç”Ÿæ”¯æŒ

**ä¸‹è½½**:
- https://alicevision.org/#meshroom

**ä½¿ç”¨**:
```powershell
# å¯ä»¥é€šè¿‡å‘½ä»¤è¡Œè°ƒç”¨
meshroom_batch --input images/ --output output/
```

---

## 3. PyTorch3D æ›¿ä»£æ–¹æ¡ˆ

### é—®é¢˜
- ç¼–è¯‘æ—¶é—´é•¿ï¼ˆ30-60 åˆ†é’Ÿï¼‰
- éœ€è¦å¤§é‡å†…å­˜

### ğŸŸ¢ æ–¹æ¡ˆ 1: Conda é¢„ç¼–è¯‘ç‰ˆæœ¬ (æ¨è)

```powershell
# ä½¿ç”¨ conda å®‰è£…é¢„ç¼–è¯‘ç‰ˆæœ¬
conda install pytorch3d -c pytorch3d

# æˆ–ä½¿ç”¨ fvcore æ¸ é“
conda install pytorch3d -c fvcore -c iopath -c conda-forge
```

### ğŸŸ¢ æ–¹æ¡ˆ 2: é¢„ç¼–è¯‘ Wheel

```powershell
# ä» PyTorch3D å®˜æ–¹ä¸‹è½½é¢„ç¼–è¯‘ wheel
# https://github.com/facebookresearch/pytorch3d/releases

pip install pytorch3d-0.7.5-cp39-cp39-win_amd64.whl
```

### ğŸŸ¡ æ–¹æ¡ˆ 3: Open3D

**ä¼˜åŠ¿**:
- âœ… æ˜“äºå®‰è£…
- âœ… æ€§èƒ½å¥½
- âš ï¸ API ä¸åŒï¼Œéœ€è¦ä¿®æ”¹ä»£ç 

**å®‰è£…**:
```powershell
pip install open3d
```

**åŠŸèƒ½å¯¹æ¯”**:
| åŠŸèƒ½ | PyTorch3D | Open3D |
|------|-----------|--------|
| ç‚¹äº‘å¤„ç† | âœ… | âœ… |
| ç½‘æ ¼æ“ä½œ | âœ… | âœ… |
| æ¸²æŸ“ | âœ… | âœ… |
| å¯å¾®åˆ† | âœ… | âŒ |
| PyTorch é›†æˆ | âœ… | éƒ¨åˆ† |

---

## 4. Kaolin æ›¿ä»£æ–¹æ¡ˆ

### é—®é¢˜
- ç¼–è¯‘å¤æ‚
- æŸäº›åŠŸèƒ½å¯èƒ½ä¸ç¨³å®š

### ğŸŸ¢ æ–¹æ¡ˆ 1: å®˜æ–¹é¢„ç¼–è¯‘ç‰ˆæœ¬

```powershell
# NVIDIA æä¾›é¢„ç¼–è¯‘ç‰ˆæœ¬
pip install kaolin -f https://nvidia-kaolin.s3.us-east-2.amazonaws.com/torch-2.1.1_cu118.html
```

### ğŸŸ¡ æ–¹æ¡ˆ 2: è·³è¿‡ Kaolin

**è¯´æ˜**: Kaolin ä¸»è¦ç”¨äºç‰¹å®šçš„ 3D æ“ä½œï¼Œå¦‚æœç¼–è¯‘å¤±è´¥ï¼Œå¯ä»¥ï¼š
1. æ³¨é‡Šæ‰ç›¸å…³ä»£ç 
2. ä½¿ç”¨ PyTorch3D çš„ç­‰æ•ˆåŠŸèƒ½
3. ä½¿ç”¨ NumPy/PyTorch æ‰‹åŠ¨å®ç°

**å½±å“**: æŸäº›é«˜çº§åŠŸèƒ½å¯èƒ½ä¸å¯ç”¨ï¼Œä½†ä¸»æµç¨‹å¯ä»¥è¿è¡Œ

---

## 5. Matte-Anything ä¾èµ–æ›¿ä»£

### Detectron2 Windows å®‰è£…

#### ğŸŸ¢ æ–¹æ¡ˆ 1: é¢„ç¼–è¯‘ Wheel (æ¨è)

```powershell
# ä½¿ç”¨å®˜æ–¹é¢„ç¼–è¯‘ç‰ˆæœ¬
pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.1/index.html
```

#### ğŸŸ¡ æ–¹æ¡ˆ 2: ä»æºç ç¼–è¯‘

```powershell
git clone https://github.com/facebookresearch/detectron2.git
cd detectron2
pip install -e .
```

### Segment Anything æ›¿ä»£

#### ğŸŸ¢ æ–¹æ¡ˆ 1: å®˜æ–¹ SAM (æ¨è)

```powershell
pip install git+https://github.com/facebookresearch/segment-anything.git
```

#### ğŸŸ¡ æ–¹æ¡ˆ 2: FastSAM

**ä¼˜åŠ¿**:
- âœ… é€Ÿåº¦æ›´å¿«
- âœ… æ˜“äºå®‰è£…

```powershell
pip install ultralytics
```

```python
from ultralytics import FastSAM

model = FastSAM('FastSAM-x.pt')
results = model(image, device='cuda', retina_masks=True, imgsz=1024)
```

### èƒŒæ™¯åˆ†å‰²æ›¿ä»£æ–¹æ¡ˆ

#### ğŸŸ¢ æ–¹æ¡ˆ 1: Rembg

```powershell
pip install rembg[gpu]
```

```python
from rembg import remove
from PIL import Image

input_image = Image.open('input.jpg')
output_image = remove(input_image)
```

#### ğŸŸ¢ æ–¹æ¡ˆ 2: U2-Net

```powershell
pip install u2net
```

---

## 6. ç¼–è¯‘å·¥å…·æ›¿ä»£

### GCC/G++ â†’ MSVC

**Windows åŸç”Ÿç¼–è¯‘å™¨**:
```powershell
# å®‰è£… Visual Studio Build Tools
# https://visualstudio.microsoft.com/downloads/

# æˆ–ä½¿ç”¨ Visual Studio Community (å…è´¹)
# é€‰æ‹© "ä½¿ç”¨ C++ çš„æ¡Œé¢å¼€å‘" å·¥ä½œè´Ÿè½½
```

**ç¯å¢ƒé…ç½®**:
```powershell
# è®¾ç½® MSVC ç¯å¢ƒ
$env:VS_PATH = "C:\Program Files\Microsoft Visual Studio\2022\Community"
$env:INCLUDE = "$env:VS_PATH\VC\Tools\MSVC\14.xx.xxxxx\include"
$env:LIB = "$env:VS_PATH\VC\Tools\MSVC\14.xx.xxxxx\lib\x64"
```

---

## 7. ç³»ç»Ÿåº“æ›¿ä»£

### Linux ç³»ç»Ÿåº“ â†’ Windows ç­‰æ•ˆ

| Linux åŒ… | Windows æ›¿ä»£ | å®‰è£…æ–¹æ³• |
|----------|-------------|----------|
| `libopencv-dev` | `opencv` | `conda install opencv` |
| `protobuf-compiler` | `protobuf` | `conda install protobuf` |
| `libgoogle-glog-dev` | `glog` | `conda install glog` |
| `libboost-all-dev` | `boost` | `conda install boost` |
| `libhdf5-dev` | `hdf5` | `conda install hdf5` |
| `libatlas-base-dev` | `mkl` | `conda install mkl` |

---

## 8. å®Œæ•´æ›¿ä»£æ–¹æ¡ˆé…ç½®

### æœ€å°ä¾èµ–é…ç½®

å¦‚æœæƒ³è¦æœ€å°åŒ–ç¼–è¯‘ï¼Œä½¿ç”¨ä»¥ä¸‹é…ç½®ï¼š

```yaml
# environment_minimal.yml
name: gaussian_splatting_hair_minimal
channels:
  - pytorch
  - conda-forge
dependencies:
  - python=3.9
  - pytorch=2.1.1
  - torchvision=0.16.1
  - pytorch-cuda=11.8
  - opencv=4.5.3
  - scikit-image=0.20.0
  - tqdm
  - tensorboard
  
  - pip:
    - mediapipe  # æ›¿ä»£ OpenPose
    - open3d     # æ›¿ä»£ PyTorch3D (å¦‚æœç¼–è¯‘å¤±è´¥)
    - rembg      # æ›¿ä»£ Matte-Anything (ç®€åŒ–ç‰ˆ)
    - gdown
    - face-alignment
```

### æ¨èé…ç½® (å¹³è¡¡)

```yaml
# environment_recommended.yml
name: gaussian_splatting_hair_recommended
channels:
  - pytorch
  - conda-forge
  - pytorch3d
dependencies:
  - python=3.9
  - pytorch=2.1.1
  - torchvision=0.16.1
  - pytorch-cuda=11.8
  - pytorch3d  # ä½¿ç”¨ conda é¢„ç¼–è¯‘ç‰ˆæœ¬
  - opencv=4.5.3
  - scikit-image=0.20.0
  - cmake=3.28.0
  - tqdm
  - tensorboardx
  - gdown
  
  - pip:
    - mediapipe  # æ›¿ä»£ OpenPose
    - openmim
    - mmcv
    - mmpose
    - face-alignment
    - git+https://github.com/facebookresearch/segment-anything.git
    - detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu118/torch2.1/index.html
    
    # ä»…ç¼–è¯‘å¿…éœ€çš„æ‰©å±•
    - ext/diff_gaussian_rasterization_hair
    - ext/simple-knn
```

---

## 9. é›†æˆæŒ‡å—

### ä¿®æ”¹ä»£ç ä»¥ä½¿ç”¨æ›¿ä»£ç»„ä»¶

#### æ›¿æ¢ OpenPose ä¸º MediaPipe

**åŸä»£ç ** (`src/preprocessing/detect_keypoints.py`):
```python
# OpenPose è°ƒç”¨
import pyopenpose as op
# ...
```

**ä¿®æ”¹å**:
```python
# MediaPipe è°ƒç”¨
import mediapipe as mp
import cv2

mp_pose = mp.solutions.pose
pose = mp_pose.Pose(static_image_mode=True, model_complexity=2)

def detect_keypoints_mediapipe(image_path):
    image = cv2.imread(image_path)
    image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
    results = pose.process(image_rgb)
    
    if results.pose_landmarks:
        keypoints = []
        for landmark in results.pose_landmarks.landmark:
            keypoints.append([
                landmark.x * image.shape[1],
                landmark.y * image.shape[0],
                landmark.visibility
            ])
        return np.array(keypoints)
    return None
```

#### ä½¿ç”¨é¢„ç¼–è¯‘ COLMAP

**ä¿®æ”¹** `src/preprocessing/colmap_estimation.py`:
```python
import subprocess
import os

def run_colmap(image_path, output_path):
    colmap_exe = "colmap"  # æˆ–æŒ‡å®šå®Œæ•´è·¯å¾„
    
    # ç‰¹å¾æå–
    subprocess.run([
        colmap_exe, "feature_extractor",
        "--database_path", f"{output_path}/database.db",
        "--image_path", image_path
    ])
    
    # ç‰¹å¾åŒ¹é…
    subprocess.run([
        colmap_exe, "exhaustive_matcher",
        "--database_path", f"{output_path}/database.db"
    ])
    
    # é‡å»º
    subprocess.run([
        colmap_exe, "mapper",
        "--database_path", f"{output_path}/database.db",
        "--image_path", image_path,
        "--output_path", output_path
    ])
```

---

## 10. æ€§èƒ½å¯¹æ¯”

### OpenPose vs MediaPipe

| æŒ‡æ ‡ | OpenPose | MediaPipe |
|------|----------|-----------|
| å®‰è£…éš¾åº¦ | ğŸ”´ å›°éš¾ | ğŸŸ¢ ç®€å• |
| Windows æ”¯æŒ | ğŸŸ¡ éœ€ç¼–è¯‘ | ğŸŸ¢ åŸç”Ÿ |
| é€Ÿåº¦ (FPS) | 15-20 | 30-40 |
| å‡†ç¡®åº¦ | ğŸŸ¢ é«˜ | ğŸŸ¢ é«˜ |
| å†…å­˜å ç”¨ | 2-3 GB | 500 MB |
| GPU è¦æ±‚ | å¿…éœ€ | å¯é€‰ |

### PyTorch3D vs Open3D

| æŒ‡æ ‡ | PyTorch3D | Open3D |
|------|-----------|--------|
| å®‰è£…éš¾åº¦ | ğŸŸ¡ ä¸­ç­‰ | ğŸŸ¢ ç®€å• |
| å¯å¾®åˆ†æ¸²æŸ“ | âœ… | âŒ |
| é€Ÿåº¦ | ğŸŸ¢ å¿« | ğŸŸ¢ å¿« |
| åŠŸèƒ½å®Œæ•´æ€§ | ğŸŸ¢ å…¨é¢ | ğŸŸ¢ å…¨é¢ |
| PyTorch é›†æˆ | âœ… åŸç”Ÿ | ğŸŸ¡ éƒ¨åˆ† |

---

## 11. æ•…éšœå†³ç­–æ ‘

```
ç¼–è¯‘å¤±è´¥ï¼Ÿ
â”œâ”€ OpenPose
â”‚  â”œâ”€ ä½¿ç”¨ MediaPipe (æ¨è)
â”‚  â”œâ”€ ä½¿ç”¨ MMPose
â”‚  â””â”€ ä¸‹è½½é¢„ç¼–è¯‘ç‰ˆæœ¬
â”‚
â”œâ”€ PyTorch3D
â”‚  â”œâ”€ conda install pytorch3d -c pytorch3d
â”‚  â”œâ”€ ä¸‹è½½é¢„ç¼–è¯‘ wheel
â”‚  â””â”€ ä½¿ç”¨ Open3D (éœ€ä¿®æ”¹ä»£ç )
â”‚
â”œâ”€ Kaolin
â”‚  â”œâ”€ ä½¿ç”¨é¢„ç¼–è¯‘ç‰ˆæœ¬
â”‚  â”œâ”€ è·³è¿‡ (æ³¨é‡Šä»£ç )
â”‚  â””â”€ ä½¿ç”¨ PyTorch3D æ›¿ä»£
â”‚
â”œâ”€ COLMAP
â”‚  â”œâ”€ ä¸‹è½½é¢„ç¼–è¯‘ç‰ˆæœ¬ (æ¨è)
â”‚  â”œâ”€ ä½¿ç”¨ OpenMVG
â”‚  â””â”€ ä½¿ç”¨ Meshroom
â”‚
â””â”€ Detectron2
   â”œâ”€ ä½¿ç”¨é¢„ç¼–è¯‘ wheel
   â””â”€ ä»æºç ç¼–è¯‘
```

---

## 12. æ¨èå®‰è£…é¡ºåº

### é˜¶æ®µ 1: åŸºç¡€ç¯å¢ƒ
```powershell
# 1. å®‰è£… CUDA 11.8
# 2. å®‰è£… Visual Studio Build Tools
# 3. å®‰è£… Miniconda
```

### é˜¶æ®µ 2: Python ç¯å¢ƒ
```powershell
conda env create -f environment_windows.yml
conda activate gaussian_splatting_hair
```

### é˜¶æ®µ 3: æ›¿ä»£ç»„ä»¶
```powershell
# ä½¿ç”¨ MediaPipe æ›¿ä»£ OpenPose
pip install mediapipe

# ä½¿ç”¨ conda PyTorch3D
conda install pytorch3d -c pytorch3d

# ä¸‹è½½é¢„ç¼–è¯‘ COLMAP
# ä» GitHub releases ä¸‹è½½
```

### é˜¶æ®µ 4: ç¼–è¯‘å¿…éœ€ç»„ä»¶
```powershell
# ä»…ç¼–è¯‘æ ¸å¿ƒç»„ä»¶
cd ext/diff_gaussian_rasterization_hair
pip install -e .

cd ../simple-knn
pip install -e .
```

### é˜¶æ®µ 5: æµ‹è¯•
```powershell
python -c "import torch; print(torch.cuda.is_available())"
python -c "import mediapipe; print('MediaPipe OK')"
python -c "import pytorch3d; print('PyTorch3D OK')"
colmap -h
```

---

## 13. æ€»ç»“

### æ¨èé…ç½®

| ç»„ä»¶ | æ¨èæ–¹æ¡ˆ | åŸå›  |
|------|----------|------|
| OpenPose | **MediaPipe** | æ˜“å®‰è£…ï¼Œæ€§èƒ½å¥½ |
| COLMAP | **é¢„ç¼–è¯‘ç‰ˆæœ¬** | é¿å…ç¼–è¯‘é—®é¢˜ |
| PyTorch3D | **Conda ç‰ˆæœ¬** | é¢„ç¼–è¯‘ï¼Œç¨³å®š |
| Kaolin | **é¢„ç¼–è¯‘æˆ–è·³è¿‡** | éæ ¸å¿ƒç»„ä»¶ |
| Detectron2 | **é¢„ç¼–è¯‘ Wheel** | å®˜æ–¹æ”¯æŒ |

### é¢„æœŸæˆåŠŸç‡

- **ä½¿ç”¨æ¨èæ–¹æ¡ˆ**: 95%
- **å®Œå…¨ä»æºç ç¼–è¯‘**: 70%
- **æ··åˆæ–¹æ¡ˆ**: 85%

---

**ç»´æŠ¤**: å®šæœŸæ›´æ–°ä»¥åæ˜ æœ€æ–°çš„æ›¿ä»£æ–¹æ¡ˆå’Œå·¥å…·
**åé¦ˆ**: æ¬¢è¿æäº¤æ–°çš„æ›¿ä»£æ–¹æ¡ˆå»ºè®®
